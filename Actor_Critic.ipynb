{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from myfrozen import frozen_lake\n",
    "import myfrozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.envs.registration import register, spec\n",
    "\n",
    "def make_environment(name,seed,rowindex,colindex):\n",
    "    register(\n",
    "            id=name,\n",
    "            entry_point='myfrozen.fl_custom:FrozenLakeEnv',\n",
    "            kwargs={'map_name': '8x8', 'is_slippery': False,\n",
    "            'seed': 123, 'rowindex': rowindex, 'colindex': colindex},\n",
    "            timestep_limit=100,\n",
    "            reward_threshold=0.78,\n",
    "            )\n",
    "    env = gym.make(name)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot(size,value):\n",
    "  my_onehot = np.zeros((size))\n",
    "  my_onehot[value] = 1.0\n",
    "  return my_onehot\n",
    "\n",
    "OBSERVATION_SPACE = env.observation_space.n\n",
    "ACTION_SPACE = env.action_space.n\n",
    "\n",
    "# Assume gridworld is always square\n",
    "OBS_SQR = int(math.sqrt(OBSERVATION_SPACE))\n",
    "STATEGRID = np.zeros((OBS_SQR,OBS_SQR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HHFHFHFF\n",
      "FFFFFFFF\n",
      "\u001b[41mS\u001b[0mFFFFFFF\n",
      "FFHFFFFF\n",
      "FFFFFFHF\n",
      "FFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFFHFFG\n"
     ]
    }
   ],
   "source": [
    "iteration = 3\n",
    "name='FO8x8-v%d' % iteration\n",
    "env = make_environment(name,iteration,7,7)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â The actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/drl/lib/python2.7/site-packages/ipykernel/__main__.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"lecun_uniform\", input_shape=(64,))`\n",
      "/anaconda/envs/drl/lib/python2.7/site-packages/ipykernel/__main__.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(128, kernel_initializer=\"lecun_uniform\")`\n",
      "/anaconda/envs/drl/lib/python2.7/site-packages/ipykernel/__main__.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"lecun_uniform\")`\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "from keras.layers import Lambda\n",
    "\n",
    "actor_model = Sequential()\n",
    "actor_model.add(Dense(ACTION_SPACE, init='lecun_uniform', input_shape=(OBSERVATION_SPACE,)))\n",
    "#actor_model.add(Lambda(lambda x: K.tf.nn.softmax(x)))\n",
    "actor_model.add(Activation('relu'))\n",
    "\n",
    "actor_model.add(Dense(128, init='lecun_uniform'))\n",
    "actor_model.add(Activation('relu'))\n",
    "\n",
    "actor_model.add(Dense(ACTION_SPACE, init='lecun_uniform'))\n",
    "#actor_model.add(Lambda(lambda x: K.tf.nn.softmax(x)))\n",
    "actor_model.add(Activation('linear'))\n",
    "\n",
    "a_optimizer = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "actor_model.compile(loss='mse', optimizer=a_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actor_model.layers[0].set_weights(lista)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/drl/lib/python2.7/site-packages/ipykernel/__main__.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"lecun_uniform\", input_shape=(64,))`\n",
      "/anaconda/envs/drl/lib/python2.7/site-packages/ipykernel/__main__.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=\"lecun_uniform\")`\n"
     ]
    }
   ],
   "source": [
    "critic_model = Sequential()\n",
    "\n",
    "critic_model = Sequential()\n",
    "critic_model.add(Dense(ACTION_SPACE, init='lecun_uniform', input_shape=(OBSERVATION_SPACE,)))\n",
    "critic_model.add(Activation('relu'))\n",
    "#critic_model.add(Dense(150, init='lecun_uniform'))\n",
    "#critic_model.add(Activation('relu'))\n",
    "critic_model.add(Dense(1, init='lecun_uniform'))\n",
    "critic_model.add(Activation('linear'))\n",
    "\n",
    "c_optimizer = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "critic_model.compile(loss='mse', optimizer=c_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HHFHFHFF\n",
      "FFFFFFFF\n",
      "\u001b[41mS\u001b[0mFFFFFFF\n",
      "FFHFFFFF\n",
      "FFFFFFHF\n",
      "FFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFFHFFG\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot out the values the critic gives for the agent being in\n",
    "# a specific state, i.e. in a specific location in the env.\n",
    "def plot_value(initial_state):\n",
    "    # Assume gridworld is always a square\n",
    "    obs_sqr = math.sqrt(OBSERVATION_SPACE)\n",
    "    np_w_cri_r = np.zeros((OBS_SQR,OBS_SQR))\n",
    "    # make a working copy.\n",
    "    working_state = initial_state.copy()\n",
    "    for x in range(0,OBS_SQR):\n",
    "        for y in range(0,OBS_SQR):\n",
    "            my_state = working_state.copy()\n",
    "            # Place the player at a given X/Y location.\n",
    "            my_state[x,y] = 1\n",
    "            # And now have the critic model predict the state value\n",
    "            # with the player in that location.\n",
    "            value = critic_model.predict(my_state.reshape(1, OBSERVATION_SPACE))\n",
    "            np_w_cri_r[x,y] = value\n",
    "    np_w_cri_r.shape\n",
    "    pylab.pcolor(np_w_cri_r)\n",
    "    pylab.title(\"Value Network\")\n",
    "    pylab.colorbar()\n",
    "    pylab.xlabel(\"X\")\n",
    "    pylab.ylabel(\"Y\")\n",
    "    pylab.gca().invert_yaxis()\n",
    "    pylab.draw()\n",
    "\n",
    "\n",
    "env.reset()\n",
    "env.render()\n",
    "plot_value(STATEGRID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import random\n",
    "import time\n",
    "\n",
    "def trainer(epochs=1000, batchSize=40, \n",
    "            gamma=0.975, epsilon=1, min_epsilon=0.1,\n",
    "            buffer=80):\n",
    "    \n",
    "    wins = 0\n",
    "    losses = 0\n",
    "    # Replay buffers\n",
    "    actor_replay = []\n",
    "    critic_replay = []\n",
    "    wins_ws = 0\n",
    "    losses_ws = 0\n",
    "    warm_start=100\n",
    "    \n",
    "    for i in range(epochs):\n",
    "\n",
    "        observation = env.reset()\n",
    "        done = False\n",
    "        reward = 0\n",
    "        info = None\n",
    "        move_counter = 0\n",
    "\n",
    "        while(not done):\n",
    "            # Get original state, original reward, and critic's value for this state.\n",
    "            orig_state = to_onehot(OBSERVATION_SPACE,observation)\n",
    "            orig_reward = reward\n",
    "            orig_val = critic_model.predict(orig_state.reshape(1,OBSERVATION_SPACE))\n",
    "\n",
    "            if (random.random() < epsilon): #choose random action\n",
    "                action = np.random.randint(0,ACTION_SPACE)\n",
    "            else: #choose best action from Q(s,a) values\n",
    "                qval = actor_model.predict( orig_state.reshape(1,OBSERVATION_SPACE) )\n",
    "                #print(qval)\n",
    "                action = (np.argmax(qval))\n",
    "                \n",
    "            #Take action, observe new state S'\n",
    "            new_observation, new_reward, done, info = env.step(action)\n",
    "            new_state = to_onehot(OBSERVATION_SPACE,new_observation)\n",
    "            # Critic's value for this new state.\n",
    "            new_val = critic_model.predict(new_state.reshape(1,OBSERVATION_SPACE))\n",
    "            \n",
    "            if not done: # Non-terminal state.\n",
    "                target = orig_reward + ( gamma * new_val)\n",
    "            else:\n",
    "                # In terminal states, the environment tells us\n",
    "                # the value directly.\n",
    "                target = orig_reward + ( gamma * new_reward )\n",
    "            \n",
    "            # For our critic, we select the best/highest value.. The\n",
    "            # value for this state is based on if the agent selected\n",
    "            # the best possible moves from this state forward.\n",
    "            # \n",
    "            # BTW, we discount an original value provided by the\n",
    "            # value network, to handle cases where its spitting\n",
    "            # out unreasonably high values.. naturally decaying\n",
    "            # these values to something reasonable.\n",
    "            if new_reward <0:\n",
    "                best_val = new_reward\n",
    "            else:\n",
    "                best_val = max((orig_val*gamma), target)\n",
    "            # Now append this to our critic replay buffer.\n",
    "            critic_replay.append([orig_state, best_val])\n",
    "            # If we are in a terminal state, append a replay for it also.\n",
    "            if done:\n",
    "                critic_replay.append( [new_state, float(new_reward)] )\n",
    "            \n",
    "            # Build the update for the Actor. The actor is updated\n",
    "            # by using the difference of the value the critic\n",
    "            # placed on the old state vs. the value the critic\n",
    "            # places on the new state.. encouraging the actor\n",
    "            # to move into more valuable states.\n",
    "            actor_delta = new_val - orig_val                \n",
    "            actor_replay.append([orig_state, action, actor_delta])\n",
    "                    \n",
    "            # Critic Replays...\n",
    "            while(len(critic_replay) > buffer): # Trim replay buffer\n",
    "                critic_replay.pop(0)\n",
    "            # Start training when we have enough samples.\n",
    "            if(len(critic_replay) >= buffer):\n",
    "                minibatch = random.sample(critic_replay, batchSize)\n",
    "                X_train = []\n",
    "                y_train = []\n",
    "                for memory in minibatch:\n",
    "                    m_state, m_value = memory\n",
    "                    y = np.empty([1])\n",
    "                    y[0] = m_value\n",
    "                    X_train.append(m_state.reshape((OBSERVATION_SPACE,)))\n",
    "                    y_train.append(y.reshape((1,)))\n",
    "                X_train = np.array(X_train)\n",
    "                y_train = np.array(y_train)\n",
    "                critic_model.fit(X_train, y_train, batch_size=batchSize, nb_epoch=1, verbose=0)\n",
    "            \n",
    "            # Actor Replays...\n",
    "            while(len(actor_replay) > buffer):\n",
    "                actor_replay.pop(0)                \n",
    "            if(len(actor_replay) >= buffer):\n",
    "                X_train = []\n",
    "                y_train = []\n",
    "                minibatch = random.sample(actor_replay, batchSize)\n",
    "                for memory in minibatch:\n",
    "                    m_orig_state, m_action, m_value = memory\n",
    "                    old_qval = actor_model.predict( m_orig_state.reshape(1,OBSERVATION_SPACE,) )\n",
    "                    y = np.zeros(( 1, ACTION_SPACE ))\n",
    "                    y[:] = old_qval[:]\n",
    "                    y[0][m_action] = m_value\n",
    "                    X_train.append(m_orig_state.reshape((OBSERVATION_SPACE,)))\n",
    "                    y_train.append(y.reshape((ACTION_SPACE,)))\n",
    "                X_train = np.array(X_train)\n",
    "                y_train = np.array(y_train)\n",
    "                actor_model.fit(X_train, y_train, batch_size=batchSize, nb_epoch=1, verbose=0)\n",
    "\n",
    "            # Bookkeeping at the end of the turn.\n",
    "            observation = new_observation\n",
    "            reward = new_reward\n",
    "            move_counter+=1\n",
    "            if done:\n",
    "                if new_reward > 0 : # Win\n",
    "                    wins += 1\n",
    "                else: # Loss\n",
    "                    losses += 1\n",
    "        if i == warm_start:\n",
    "            wins_ws = deepcopy(wins)\n",
    "            losses_ws = deepcopy(losses)\n",
    "        # Finised Epoch\n",
    "        clear_output(wait=True)\n",
    "        print(\"Game #: %s\" % (i,))\n",
    "        print(\"Moves this round %s\" % move_counter)\n",
    "        print(\"Final Position:\")\n",
    "        env.render()\n",
    "        print(\"Wins/Losses %s/%s\" % (wins, losses))\n",
    "        print(\"Wins/Losses before WS %s/%s\" % (wins_ws, losses_ws))\n",
    "        if epsilon > min_epsilon:\n",
    "            epsilon -= (1.0/epochs)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import random\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "def trainer(epochs=1000, batchSize=40, \n",
    "            gamma=0.975, epsilon=1, min_epsilon=0.1,\n",
    "            buffer=80,policy=np.random.random((64,4))):\n",
    "    \n",
    "    wins = 0\n",
    "    losses = 0\n",
    "    \n",
    "    wins_ws = 0\n",
    "    losses_ws = 0\n",
    "    # Replay buffers\n",
    "    actor_replay = []\n",
    "    critic_replay = []\n",
    "    warm_start=100\n",
    "    \n",
    "    for i in range(epochs):\n",
    "\n",
    "        observation = env.reset()\n",
    "        done = False\n",
    "        reward = 0\n",
    "        info = None\n",
    "        move_counter = 0\n",
    "\n",
    "        while(not done):\n",
    "            # Get original state, original reward, and critic's value for this state.\n",
    "            orig_state = to_onehot(OBSERVATION_SPACE,observation)\n",
    "            orig_reward = reward\n",
    "            orig_val = critic_model.predict(orig_state.reshape(1,OBSERVATION_SPACE))\n",
    "            \n",
    "            #if i < warm_start:\n",
    "            #    obs_predict = np.squeeze(orig_state)\n",
    "            #    index, = np.where(obs_predict == 1.)\n",
    "            #    action = np.argmax(policy[index,:])\n",
    "            \n",
    "            if (random.random() < epsilon): #choose random action\n",
    "                action = np.random.randint(0,ACTION_SPACE)\n",
    "            else:\n",
    "                if i < warm_start:\n",
    "                    obs_predict = np.squeeze(orig_state)\n",
    "                    index, = np.where(obs_predict == 1.)\n",
    "                    action = np.argmax(policy[index,:])\n",
    "                else: #choose best action from Q(s,a) values\n",
    "                    qval = actor_model.predict( orig_state.reshape(1,OBSERVATION_SPACE) )\n",
    "                    action = (np.argmax(qval))\n",
    "                \n",
    "            #Take action, observe new state S'\n",
    "            new_observation, new_reward, done, info = env.step(action)\n",
    "            new_state = to_onehot(OBSERVATION_SPACE,new_observation)\n",
    "            # Critic's value for this new state.\n",
    "            new_val = critic_model.predict(new_state.reshape(1,OBSERVATION_SPACE))\n",
    "            \n",
    "            if not done: # Non-terminal state.\n",
    "                target = orig_reward + ( gamma * new_val)\n",
    "            else:\n",
    "                # In terminal states, the environment tells us\n",
    "                # the value directly.\n",
    "                target = orig_reward + ( gamma * new_reward )\n",
    "            \n",
    "            # For our critic, we select the best/highest value.. The\n",
    "            # value for this state is based on if the agent selected\n",
    "            # the best possible moves from this state forward.\n",
    "            # \n",
    "            # BTW, we discount an original value provided by the\n",
    "            # value network, to handle cases where its spitting\n",
    "            # out unreasonably high values.. naturally decaying\n",
    "            # these values to something reasonable.\n",
    "            if new_reward <0:\n",
    "                best_val = new_reward\n",
    "            else:\n",
    "                best_val = max((orig_val*gamma), target)\n",
    "            # Now append this to our critic replay buffer.\n",
    "            critic_replay.append([orig_state, best_val])\n",
    "            # If we are in a terminal state, append a replay for it also.\n",
    "            if done:\n",
    "                critic_replay.append( [new_state, float(new_reward)] )\n",
    "            \n",
    "            # Build the update for the Actor. The actor is updated\n",
    "            # by using the difference of the value the critic\n",
    "            # placed on the old state vs. the value the critic\n",
    "            # places on the new state.. encouraging the actor\n",
    "            # to move into more valuable states.\n",
    "            actor_delta = new_val - orig_val                \n",
    "            actor_replay.append([orig_state, action, actor_delta])\n",
    "                    \n",
    "            # Critic Replays...\n",
    "            while(len(critic_replay) > buffer): # Trim replay buffer\n",
    "                critic_replay.pop(0)\n",
    "            # Start training when we have enough samples.\n",
    "            if(len(critic_replay) >= buffer):\n",
    "                minibatch = random.sample(critic_replay, batchSize)\n",
    "                X_train = []\n",
    "                y_train = []\n",
    "                for memory in minibatch:\n",
    "                    m_state, m_value = memory\n",
    "                    y = np.empty([1])\n",
    "                    y[0] = m_value\n",
    "                    X_train.append(m_state.reshape((OBSERVATION_SPACE,)))\n",
    "                    y_train.append(y.reshape((1,)))\n",
    "                X_train = np.array(X_train)\n",
    "                y_train = np.array(y_train)\n",
    "                critic_model.fit(X_train, y_train, batch_size=batchSize, nb_epoch=1, verbose=0)\n",
    "            \n",
    "            # Actor Replays...\n",
    "            while(len(actor_replay) > buffer):\n",
    "                actor_replay.pop(0)                \n",
    "            if(len(actor_replay) >= buffer):\n",
    "                X_train = []\n",
    "                y_train = []\n",
    "                minibatch = random.sample(actor_replay, batchSize)\n",
    "                for memory in minibatch:\n",
    "                    m_orig_state, m_action, m_value = memory\n",
    "                    old_qval = actor_model.predict( m_orig_state.reshape(1,OBSERVATION_SPACE,) )\n",
    "                    y = np.zeros(( 1, ACTION_SPACE ))\n",
    "                    y[:] = old_qval[:]\n",
    "                    y[0][m_action] = m_value\n",
    "                    X_train.append(m_orig_state.reshape((OBSERVATION_SPACE,)))\n",
    "                    y_train.append(y.reshape((ACTION_SPACE,)))\n",
    "                X_train = np.array(X_train)\n",
    "                y_train = np.array(y_train)\n",
    "                actor_model.fit(X_train, y_train, batch_size=batchSize, nb_epoch=1, verbose=0)\n",
    "\n",
    "            # Bookkeeping at the end of the turn.\n",
    "            observation = new_observation\n",
    "            reward = new_reward\n",
    "            move_counter+=1\n",
    "            if done:\n",
    "                if new_reward > 0 : # Win\n",
    "                    wins += 1\n",
    "                else: # Loss\n",
    "                    losses += 1\n",
    "        if i == warm_start:\n",
    "            wins_ws = deepcopy(wins)\n",
    "            losses_ws = deepcopy(losses)\n",
    "        # Finised Epoch\n",
    "        clear_output(wait=True)\n",
    "        print(\"Game #: %s\" % (i,))\n",
    "        print(\"Moves this round %s\" % move_counter)\n",
    "        print(\"Final Position:\")\n",
    "        env.render()\n",
    "        print(\"Wins/Losses %s/%s\" % (wins, losses))\n",
    "        print(\"Wins/Losses before WS %s/%s\" % (wins_ws, losses_ws))\n",
    "        if epsilon > min_epsilon:\n",
    "            epsilon -= (1.0/epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game #: 999\n",
      "Moves this round 14\n",
      "Final Position:\n",
      "  (Down)\n",
      "HHFHFHFF\n",
      "FFFFFFFF\n",
      "SFFFFFFF\n",
      "FFHFFFFF\n",
      "FFFFFFHF\n",
      "FFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFFHFF\u001b[41mG\u001b[0m\n",
      "Wins/Losses 415/585\n",
      "Wins/Losses before WS 2/99\n",
      "CPU times: user 9min 29s, sys: 1min 10s, total: 10min 40s\n",
      "Wall time: 8min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer(epochs=1000,buffer=40,batchSize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "trainer() got an unexpected keyword argument 'policy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-22c252c11da3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'trainer(epochs=1000,buffer=30,batchSize=20,policy=gen_imgs)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/drl/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/drl/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/drl/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: trainer() got an unexpected keyword argument 'policy'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer(epochs=1000,buffer=30,batchSize=20,policy=gen_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â What the Value network has learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HHFHFHFF\n",
      "FFFFFFFF\n",
      "\u001b[41mS\u001b[0mFFFFFFF\n",
      "FFHFFFFF\n",
      "FFFFFFHF\n",
      "FFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFFHFFG\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "env.render()\n",
    "plot_value(STATEGRID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FF\u001b[41mS\u001b[0mFFFFF\n",
      "FFFFFHFF\n",
      "FFFFFFFH\n",
      "FFHFFFFF\n",
      "FFFFFHFF\n",
      "FFFFFFHF\n",
      "FFFFHFFF\n",
      "FFFGFFFF\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAEWCAYAAABLzQ1kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAG0xJREFUeJzt3Xu0nXV95/H355yES0K4BiwmKDil2AyrBScGlVGxgAZF6MxSh1jp6LKmqzMo3hfqDFqms5ZVx3ZmldpmFEHkIuJlUkwNzNR4a8WEi0i4aBqRHEDCReSmJDnnM3/sJ3RzPOfsfZL97OcHz+e11rOyn2c/5/f7sjn57l9+t0e2iYiI8ow0HUBEREwtCToiolBJ0BERhUqCjogoVBJ0REShkqAjIgqVBB2zIulwSZY0p+lYmiRpnaQ/ajqOeGZLgm4ZSWslnTfF9dMl/azJxCvpDkn3Sprfde2PJK3r8+cvlPRntQUYMWRJ0O1zIXCmJE26fiZwie0dww/pKeYAZzccw7TUkb83MRT5RWufrwIHAi/deUHSAcCpwOeq89dIukHSw5K2SPrIdIVVrd6Tus4/IunzXecvkvSPkh6S9ANJJ/SI7+PAeyXtP019z5d0jaQHJd0u6Q3V9ZXAHwDvl/SopL+T9BZJf9f1s5skXdF1vkXSMdXrl0haL+kX1Z8v6bpvnaT/Lum7wOPA8ybFdKikmyS9t8d/W8SsJEG3jO1fAlcAf9h1+Q3AbbZ/UJ0/Vr2/P/Aa4E8k/f5s65K0CPga8Gd0vhTeC3xJ0sEz/NgGYF117+Ty5gPXAJcChwArgL+W9K9trwIuAT5mex/brwW+CbxU0oikQ4G5wPFVWc8D9gFuknRgFef/Ag4CPgl8TdJBXdWfCawEFgA/7Yrp8Kqev7L9ib4/nIg+JEG300XA6yXtXZ3/YXUNANvrbP/Q9oTtm4DLgJfvQj1vAtbYXlOVdQ2dBPzqHj93LvD2KRL5qcAdtj9re4ft64EvAa+bqhDbm4FHgGOq+NcCd0l6fnX+bdsTdL6Efmz74qrcy4DbgNd2FXeh7Y3V+9ura0vofJl8uPqCiBioVo/Et5Xt70i6Dzhd0veBFwL/fuf7ko4DPgocDewB7Al8cReqei6dL4LuRDcX+EaP+G6WdBVwDnDrpPKOk/RQ17U5wMUzFPdN4ATgN6vXD9FJzi+uzgGeTVeruPJTYFHX+ZYpyv4DYBNw5Qz1R+yytKDb63N0Ws5nAlfbvrfrvUuB1cBhtvcD/gaYPKi402PAvK7z3+h6vQW42Pb+Xcd82x/tI74PA2/j15PkNyeVt4/tP6nen2prxp0J+qXV62/SSdAv518S9N10kn+35wB3dZ1PVfZHgPuBSyWN9vHfFDErSdDt9TngJDpJ8KJJ7y0AHrT9K0nLgDfOUM6NwBmS5kpaylO7Gz4PvFbSqySNStpL0gmSFvcKzvYm4AvAO7ouXwX8lqQzq/rmSnqhpN+u3r+XSQN4dJLwK4C9bY8B3waW0+lrvqG6Z01V7hslzZH0H+h0X1zVI8ztwOuB+cDFmd0Rg5ZfqJayfQfwj3SSy+pJb/8n4DxJj9DpD76C6f1X4F8BPwf+lE7re2cdW4DTgQ8C99FpAb+P/n/vzqvi21neI8ArgTPotHp/Bvw5nS4YgM8AS6oZI1+tfuZHwKN0EjO2HwY2A9+1PV5de4BO//Z7gAeA9wOn2r6/V4C2t9HpHjoEuCBJOgZJ2bA/IqJM+baPiChUrQla0vJqMcEmSefUWVdExDNNbV0c1aj2j4CTgTFgPbDC9i21VBgR8QxTZwt6GbDJ9uZqIOVyOgNGERHRhzoXqiziqZP7x4DjJt9U7aGwEmDu3qP/5oDD960xpN5G1Pyg6ciUU26Hr4TPYsLTTb8enicmyljPNXdkvOkQ2D5RxnTvB2574H7bM20Z0NOrXjHfDzzY32d63U1PrLW9fHfq2xV1/uZN9Tfr1/7GV0tkVwE8a8mBfuOlr6wxpN7mjWxrtH6APUea3lCuY97oE02HwBMTc5sOgU2P71YeGJhn7flI0yFw7xMLmg4BgAuXXTh55eesPfDgON9f+5y+7h099McLd7e+XVFngh4DDus6X0xn7mpEROMMTDDRdBgzqjNBrweOlHQEnSWzZzDzirSIiKExZrub7zaaSW0J2vYOSWfR2UFsFLjA9sa66ouImK02t6CxvYbOPgcREUUxZrzwldRlDE9HRDRgopAZU9NJgo6IVjIwngQdEVGmtKAjIgpkYHv6oCMiymOcLo6IiCIZxsvOz0nQEdFOnZWEZUuCjoiWEuPTPgu5DEnQEdFKnUHCJOiIiOJ05kEnQUdEFKmE/cZnkgQdEa2UFnRERKGMGK/3udm7LQk6IlorXRwREQUyYpvLeMbidJKgI6KVOgtV0sUREVGkDBJGRBTIFuMuuwVdW3SSLpC0VdLNddUREbE7JlBfR1Pq/Pq4EFheY/kREbusM0g4p6+jKXU+1ftbkg6vq/yIiN2RQcJZmqMJDpjzeNNhNG7B6K+aDgGABaO/bDoEto00/yt6z4kHNx0CAM/+TvObYx68x6NNhzBQ45kHPTNJK4GVAPsdunfD0UREWzwdVhI2Hp3tVbaX2l46/4A9mg4nIlpkwiN9HU1pvAUdEdGEzmZJjbdRZ1TnNLvLgH8CjpI0JumtddUVETFbRmz3aF9HU+qcxbGirrIjInaXTfELVdLFEREt1ewilH4kQUdEK5m0oCMiilX6IGESdES0klE27I+IKJGB7Q3us9GPsqOLiKiNsh90RESJDI2uEuxH2dFFRNRovGpF9zr6IWm5pNslbZJ0zhTvP0fSNyTdIOkmSa/uVWZa0BHRSrYG1oKWNAqcD5wMjAHrJa22fUvXbf8FuML2pyQtAdYAh89UbhJ0RLRSZ5BwYMu4lwGbbG8GkHQ5cDrQnaAN7Fu93g+4u1ehSdAR0VKzeibhQkkbus5X2V7Vdb4I2NJ1PgYcN6mMjwBXS3o7MB84qVelSdAR0UqdQcK+Z3Hcb3vpDO9PVZAnna8ALrT9PyS9GLhY0tG2p30SQxJ0RLTWAFcSjgGHdZ0v5te7MN5K9ZxW2/8kaS9gIbB1ukIziyMiWmnnSsJ+jj6sB46UdISkPYAzgNWT7rkTOBFA0m8DewH3zVRoWtAR0VqDemis7R2SzgLWAqPABbY3SjoP2GB7NfAe4H9Lehed7o83257cDfIUSdAR0Uo2bJ8YXCeC7TV0ps51Xzu36/UtwPGzKTMJOiJaqdPFUXYvbxJ0RLRW9uKIiCjQLKfZNaLOh8YeVq07v1XSRkln11VXRMTsdbo4+jmaUmcLegfwHtvXS1oAXCfpmklr0yMiGtPaZxLavge4p3r9iKRb6SyHnDZBz9UOFu/xYF0h9eUX4/MarR9gwegvmw4BgP1GH286BB4Z37vpEPh36zc3HQIAY9sObDoEfviqQ5oOYWA6szgGthdHLYbSBy3pcOBY4Nop3lsJrAQ46Nl7DiOciIinxSOvau9ckbQP8CXgnbYfnvy+7VW2l9peus8BGbOMiOGZQH0dTak1I0qaSyc5X2L7y3XWFRExG0+HWRy1JWhJAj4D3Gr7k3XVExGxq9q8UOV44Ezgh5JurK59sFoOGRHRKFvsaGuCtv0dpt4jNSKiCK3t4oiIKFmr+6AjIkqXBB0RUaCnwzzoJOiIaK3WLvWOiCiZDTsGuGF/HZKgI6K10sUREVGg9EFHRBTMSdAREWXKIGFERIHs9EFHRBRKjGcWR0REmdIHHRFRoOzFERFRKnf6oUuWBB0RrZVZHBERBXIGCSMiypUujoiIQrV2FoekvYBvAXtW9Vxp+8N11RcRMRt2ixM08ATwe7YflTQX+I6kv7f9vRrrjIjoW2un2dk28Gh1Orc6ZuzxGZWZP/JEXSH1ZbtHG60f4AvP/42mQwDgA5tvajoERploOgQArnvsiKZDYN7otqZDYK8rm46g8m8HU0zpfdC1DmFKGpV0I7AVuMb2tVPcs1LSBkkbHn5wR53hROySEpJzDJ4RExMjfR1NqbVm2+O2jwEWA8skHT3FPatsL7W9dN8DM2YZEcPjPo9+SFou6XZJmySdM809b5B0i6SNki7tVeZQMqLthyStA5YDNw+jzoiIGQ1wkFDSKHA+cDIwBqyXtNr2LV33HAl8ADje9s8lHdKr3Npa0JIOlrR/9Xpv4CTgtrrqi4iYtcE1oZcBm2xvtr0NuBw4fdI9bwPOt/1zANtbexVaZwv6UOCi6ptlBLjC9lU11hcRMSuzaEEvlLSh63yV7VVd54uALV3nY8Bxk8r4LQBJ3wVGgY/Y/vpMldY5i+Mm4Ni6yo+I2B0GJib6TtD32146w/tTFTS57T0HOBI4gc643LclHW37oekKLXshekREXQxY/R29jQGHdZ0vBu6e4p7/Y3u77Z8At9NJ2NNKgo6I1rL7O/qwHjhS0hGS9gDOAFZPuuerwCsAJC2k0+WxeaZCk6Ajor0GNEhoewdwFrAWuJXOmNtGSedJOq26bS3wgKRbgG8A77P9wEzlZuJxRLSUBroXh+01wJpJ187tem3g3dXRlyToiGivwpd6J0FHRDsZ3P8sjkYkQUdEiyVBR0SUKV0cERGFSoKOiCjQzoUqBUuCjojWKn3D/iToiGivzOKIiCiT0oKOiCjQbB6X0pAk6Ihoqb53qmtMEnREtFda0BERhZpoOoCZJUFHRDs9DeZB174ftKRRSTdIyvMII6Iocn9HU6ZN0JLWSDp8AHWcTWcD64iIsgzuqd61mKkFfSFwtaQPSZq7K4VLWgy8Bvj0rvx8RESbTdsHbfsKSV8DzgU2SLqYri5125/so/y/BN4PLJjuBkkrgZUAhzx7DvuPPtZn6PU4eM7DjdYP8Ik7ZnxMWauMu/mnsn3/mNGmQwDgud9f2HQIHLXg3qZDGKjSF6r0+u3fDjwG7EknyXYfM5J0KrDV9nUz3Wd7le2ltpfud2DGLCNiSExnqXc/R0OmzYiSlgOfpPNk2hfYfnyWZR8PnCbp1cBewL6SPm/7TbscbUTEIBXegp6pyfoh4PW2N+5KwbY/AHwAQNIJwHuTnCOiJKV3cczUB/3SYQYSETF0T9cEPUi21wHrhlFXRETfkqAjIsrT9CKUfiRBR0R7ZcP+iIgypQUdEVGqJOiIiAKlDzoiomBJ0BERZVLhG/Y3vxNNRERMKS3oiGivdHFERBQog4QREQVLgo6IKFThCTqDhBHRSqIzi6Ofo6/ypOWSbpe0SdI5M9z3OkmWtLRXmUnQEdFOfT7Ru59+akmjwPnAKcASYIWkJVPctwB4B3BtPyEmQUdEew3uqd7LgE22N9veBlwOnD7Fff8N+Bjwq34KTYKOiPbqP0EvlLSh61g5qaRFwJau87Hq2pMkHQscZvuqfsPLIGFEtNYsptndb3umPuOp9i19snRJI8BfAG/uu0bSgo6INhtcF8cYcFjX+WLg7q7zBcDRwDpJdwAvAlb3GiistQVdBfIIMA7s6PENFBExPB7oXhzrgSMlHQHcBZwBvPHJquxfAAt3nktaR+dB2htmKnQYXRyvsH3/EOqJiJidAc2Dtr1D0lnAWmAUuMD2RknnARtsr96VctMHHRGtNcil3rbXAGsmXTt3mntP6KfMuhO0gaslGfhb26sm31CNhq4EeNaiURaM9DX7pDb7jzzRaP0A8wrZA7GMKB5tOgBW/nhz0yEAcMFLljUdAi/81k+aDmGwCl9JWHeCPt723ZIOAa6RdJvtb3XfUCXtVQDP/509C/+4IuIZo/8BwMbUOovD9t3Vn1uBr9CZzB0R0TgxuJWEdaktQUuaXy1rRNJ84JXAzXXVFxExW6Un6Dq7OJ4FfEXSznoutf31GuuLiJidwrs4akvQtjcDv1tX+RERu62tCToiomh5okpERMGSoCMiylTIkoNpJUFHRGuliyMiokRPg4UqSdAR0V5J0BER5dm5krBkSdAR0VqaKDtDJ0FHRDulDzoiolzp4oiIKFUSdEREmdKCjogoVRJ0RESBBvtU71okQUdEK2UedEREyVx2hk6CjojWSgs6IqJET4OFKrU+1VvS/pKulHSbpFslvbjO+iIiZkMT/R1NqbsF/T+Br9t+naQ9gHk11xcR0bfWzuKQtC/wMuDNALa3Advqqi8iYlZMqwcJnwfcB3xW0u8C1wFn236s+yZJK4GVAIcuGmX/kSdqDKm3BSPNf6Xup7lNhwDAdpr/LP74OS9qOgTe8qM7mw4BgDO/e33TIbDdo02HMFClDxLW2Qc9B3gB8CnbxwKPAedMvsn2KttLbS898MBau8QjIp7KfR4NqTMjjgFjtq+tzq+kk7AjIhq3c6FKP0dTakvQtn8GbJF0VHXpROCWuuqLiJgVG030dzSl7lkcbwcuqWZwbAbeUnN9ERH9K7wPutYEbftGYGmddURE7KrSBwmzkjAi2slA4c8kzLSJiGivAc7ikLRc0u2SNkn6tRlrkt4t6RZJN0n6f5Ke26vMJOiIaK1BzeKQNAqcD5wCLAFWSFoy6bYbgKW2f4fOrLaP9So3CToiWmuAsziWAZtsb65WTV8OnN59g+1v2H68Ov0esLhXoUnQEdFO/XZvdPLzQkkbuo6Vk0pbBGzpOh+rrk3nrcDf9woxg4QR0UqdhSp9DxLeb3umGWma4tqUhUt6E53ZbS/vVWkSdES01+C2mxkDDus6XwzcPfkmSScBHwJebrvnxkNJ0BHRWrNoQfeyHjhS0hHAXcAZwBufUpd0LPC3wHLbW/spNH3QEdFOs+uDnrkoewdwFrAWuBW4wvZGSedJOq267ePAPsAXJd0oaXWvctOCjoiWGuw+G7bXAGsmXTu36/VJsy0zCToi2qvFG/ZHRJTLLX7kVURE8dKCjogoVNn5OQk6ItpLE2X3cSRBR0Q7mUEuVKlFEnREtJLwIBeq1CIJOiLaq/AEXdtKQklHVatldh4PS3pnXfVFRMya3d/RkNpa0LZvB46BJzezvgv4Sl31RUTMSvqgn3Qi8M+2fzqk+iIiesosjo4zgMt63TQis2Ck2Q9sgZrvlt9nZK+mQyjGitvuaToEHhkv4//HeAF7m80f6blD5tNIs90X/aj9/7ikPYDTgC9O8/7KnU8pePCBsr/NIuIZxBTfBz2Mr+RTgOtt3zvVm7ZX2V5qe+mBBzXfQoiIFpno82jIMP49v4I+ujciIoat9HnQtTZZJc0DTga+XGc9ERG7pPAujlpb0NUjxg+qs46IiF1iw3jZ417NT1mIiGhK4V0cSdAR0V5J0BERBTIwwGcS1iEJOiJayuD0QUdElMdkkDAioljpg46IKFQSdEREicrfLCkJOiLayUC2G42IKFRa0BERJcpS74iIMhmcedAREYXKSsKIiEKlDzoiokB2ZnFERBQrLeiIiBIZj483HcSMkqAjop2eBtuN5jHaEdFenujv6IOk5ZJul7RJ0jlTvL+npC9U718r6fBeZdb90Nh3Sdoo6WZJl0naq876IiL6ZcAT7uvoRdIocD5wCrAEWCFpyaTb3gr83PZvAn8B/HmvcmtL0JIWAe8Alto+GhgFzqirvoiIWbEH2YJeBmyyvdn2NuBy4PRJ95wOXFS9vhI4UZJmKrTuPug5wN6StgPzgLtrri8iom+zGCRcKGlD1/kq26u6zhcBW7rOx4DjJpXx5D22d0j6BXAQcP90ldaWoG3fJekTwJ3AL4GrbV89+T5JK4GV1ekTz1n8s5vriqlPC5nhAxuiEuIoIIYfFxADUMRnUUQMUEYcR+1uAY/w87X/11cu7PP2+20vn+H9qVrCk/tG+rnnKWpL0JIOoNOkPwJ4CPiipDfZ/vxTout8C62qfmaD7aV1xdSPEmIoJY7EUFYcJcRQShyTWrO7pEfCna0x4LCu88X8eo/BznvGJM0B9gMenKnQOgcJTwJ+Yvs+29uBLwMvqbG+iIimrAeOlHSEpD3ojLetnnTPauA/Vq9fB/yDPfNKmTr7oO8EXiRpHp0ujhOB3f7Wi4goTdWnfBawls6EiAtsb5R0HrDB9mrgM8DFkjbRaTn3nDRRZx/0tZKuBK4HdgA3UHVlzKDX+8NQQgxQRhyJ4V+UEEcJMUAZcZQQw1PYXgOsmXTt3K7XvwJeP5sy1aOFHRERDclKwoiIQiVBR0QUqogE3WsN+5BiuEDSVkmNzcOWdJikb0i6tVoif3ZDcewl6fuSflDF8adNxFHFMirpBklXNRjDHZJ+KOnGQUzv2sUY9pd0paTbqt+PFzcQw1HVZ7DzeFjSOxuIozVbSDTeB12tYf8RcDKdeYLrgRW2bxlyHC8DHgU+Vy1NHzpJhwKH2r5e0gLgOuD3G/gsBMy3/aikucB3gLNtf2+YcVSxvBtYCuxr+9Rh11/FcAedLQsaW5wh6SLg27Y/XU3jmmf7oQbjGQXuAo6z/dMh1ruIzu/jEtu/lHQFsMb2hcOKYZhKaEH3s4a9dra/RY9J40OI4R7b11evHwFupbM8dNhx2Paj1enc6hj6N7mkxcBrgE8Pu+6SSNoXeBmdaVrY3tZkcq6cCPzzMJNzl51bSMzhGb6FRAkJeqo17ENPSqWptiI8Fri2ofpHJd0IbAWusd1EHH8JvB9o+rlEBq6WdF21NcGwPQ+4D/hs1d3zaUnzG4ij2xnAZcOu1PZdwM4tJO4BfjHVFhLPFCUk6FmvT3+mk7QP8CXgnbYfbiIG2+O2j6GzZHWZpKF2+0g6Fdhq+7ph1juN422/gM5Wkv+56g4bpjnAC4BP2T4WeAxoZKwGoOpiOQ34YgN1d28h8WxgvqQ3DTuOYSkhQfezhr01qj7fLwGX2P5y0/FU/5ReBwxy34J+HA+cVvX/Xg78nqTPz/wj9bB9d/XnVuArdLrlhmkMGOv6V8yVdBJ2U04Brrd9bwN1t2oLiRISdD9r2FuhGpz7DHCr7U82GMfBkvavXu9N5y/FbcOMwfYHbC+2fTid34l/sD30lpKk+dWALVW3wiuBoc70sf0zYIuknTu4nQgMdeB4khU00L1ReXILiervy4l0xmqekRp/JuF0a9iHHYeky4AT6Oz7OgZ82PZnhhzG8cCZwA+r/l+AD1ZLSIfpUOCiaqR+BLjCdmPT3Br2LOAr1b7qc4BLbX+9gTjeDlxSNWI2A29pIAaqvXVOBv64ifp3cQuJp63Gp9lFRMTUSujiiIiIKSRBR0QUKgk6IqJQSdAREYVKgo6IKFQSdBSn2tXvJ5IOrM4PqM6f23RsEcOUBB3Fsb0F+BTw0erSR4FVDW3ME9GYzIOOIlVL3q8DLgDeBhxb7XYY0RqNrySMmIrt7ZLeB3wdeGWSc7RRujiiZKfQ2VKykQcoRDQtCTqKJOkYOns+vAh4V/W0mYhWSYKO4lS7lH2Kzn7YdwIfp7NJe0SrJEFHid4G3Gn7mur8r4HnS3p5gzFFDF1mcUREFCot6IiIQiVBR0QUKgk6IqJQSdAREYVKgo6IKFQSdEREoZKgIyIK9f8B+RXXCooI7CwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "env.render()\n",
    "plot_value(STATEGRID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Showing Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HHFHFHFF\n",
      "FFFFFFFF\n",
      "\u001b[41mS\u001b[0mFFFFFFF\n",
      "FFHFFFFF\n",
      "FFFFFFHF\n",
      "FFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFFHFFG\n",
      "[[u'>' u'v' u'^' u'v' u'v' u'v' u'v' u'>']\n",
      " [u'>' u'>' u'v' u'>' u'v' u'>' u'>' u'v']\n",
      " [u'>' u'v' u'>' u'>' u'v' u'v' u'v' u'v']\n",
      " [u'>' u'v' u'v' u'v' u'>' u'>' u'>' u'v']\n",
      " [u'>' u'v' u'>' u'>' u'>' u'v' u'v' u'v']\n",
      " [u'>' u'>' u'>' u'>' u'>' u'>' u'>' u'v']\n",
      " [u'>' u'>' u'>' u'>' u'>' u'>' u'>' u'v']\n",
      " [u'>' u'^' u'^' u'^' u'v' u'v' u'>' u'v']]\n"
     ]
    }
   ],
   "source": [
    "A2A=['<','v','>','^']\n",
    "def show_policy(initial_state):\n",
    "    grid = np.zeros((OBS_SQR,OBS_SQR), dtype='<U2')\n",
    "    #working_state = initial_state.copy()\n",
    "    #p = findLoc(working_state, np.array([0,0,0,1]))\n",
    "   #working_state[p[0],p[1]] = np.array([0,0,0,0])\n",
    "    for x in range(0,OBS_SQR):\n",
    "        for y in range(0,OBS_SQR):\n",
    "            #for a in range(0, 4):\n",
    "            my_state = initial_state.copy()\n",
    "            my_state[x,y] = 1\n",
    "            #\n",
    "            obs_predict = my_state.reshape(1,OBSERVATION_SPACE,)\n",
    "            qval = actor_model.predict(obs_predict)\n",
    "            #print(obs_predict)\n",
    "            \n",
    "            action = (np.argmax(qval))\n",
    "            grid[x,y] = A2A[action]\n",
    "    grid\n",
    "    return grid\n",
    "\n",
    "env.reset()\n",
    "env.render()\n",
    "print(show_policy(STATEGRID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FF\u001b[41mS\u001b[0mFFFFF\n",
      "FFFFFHFF\n",
      "FFFFFFFH\n",
      "FFHFFFFF\n",
      "FFFFFHFF\n",
      "FFFFFFHF\n",
      "FFFFHFFF\n",
      "FFFGFFFF\n",
      "[[u'v' u'v' u'v' u'v' u'v' u'>' u'v' u'v']\n",
      " [u'v' u'v' u'v' u'v' u'v' u'^' u'^' u'^']\n",
      " [u'v' u'v' u'>' u'v' u'v' u'<' u'<' u'<']\n",
      " [u'v' u'<' u'>' u'v' u'v' u'^' u'v' u'<']\n",
      " [u'v' u'v' u'v' u'v' u'<' u'v' u'^' u'v']\n",
      " [u'v' u'v' u'v' u'v' u'<' u'<' u'>' u'>']\n",
      " [u'v' u'v' u'v' u'v' u'>' u'^' u'<' u'v']\n",
      " [u'>' u'>' u'>' u'<' u'v' u'v' u'>' u'v']]\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "env.render()\n",
    "print(show_policy(STATEGRID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Down)\n",
      "FFSFFFFF\n",
      "FFFFFHFF\n",
      "FFFFFFFH\n",
      "FFHFFFFF\n",
      "FFFFFHFF\n",
      "FFFFFFHF\n",
      "FFFFHFFF\n",
      "FFF\u001b[41mG\u001b[0mFFFF\n"
     ]
    }
   ],
   "source": [
    "def play(render_every_step=False):\n",
    "    observation = env.reset()\n",
    "    done = False\n",
    "    reward = 0.0\n",
    "    max_moves = 40\n",
    "    move_counter = 0\n",
    "    while not done and move_counter < max_moves:\n",
    "        state = to_onehot(OBSERVATION_SPACE,observation)\n",
    "        qval = actor_model.predict( state.reshape(1,OBSERVATION_SPACE) )\n",
    "        action = (np.argmax(qval))\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        #print(A2A[action])\n",
    "        if render_every_step:\n",
    "            env.render()\n",
    "        move_counter += 1\n",
    "    env.render()\n",
    "\n",
    "play(render_every_step=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sampling from GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/drl/lib/python2.7/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "#from time import sleep\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import math\n",
    "import gym\n",
    "import myfrozen\n",
    "import pickle\n",
    "import img_utils\n",
    "import os\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, Lambda\n",
    "from keras.layers.advanced_activations import LeakyReLU, Softmax\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/drl/lib/python2.7/site-packages/keras/engine/saving.py:270: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "generator = load_model('models/policies/generator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'v' u'<' u'<' u'<' u'<' u'<' u'<' u'<']\n",
      " [u'v' u'<' u'<' u'<' u'<' u'<' u'<' u'<']\n",
      " [u'v' u'<' u'<' u'v' u'<' u'<' u'<' u'<']\n",
      " [u'v' u'<' u'<' u'v' u'<' u'<' u'<' u'<']\n",
      " [u'v' u'<' u'<' u'v' u'<' u'<' u'<' u'<']\n",
      " [u'v' u'<' u'<' u'<' u'<' u'<' u'<' u'<']\n",
      " [u'<' u'<' u'<' u'<' u'<' u'<' u'<' u'v']\n",
      " [u'<' u'^' u'<' u'<' u'<' u'<' u'<' u'<']]\n"
     ]
    }
   ],
   "source": [
    "def show_policy(q):\n",
    "    A2A=['<','v','>','^']\n",
    "    grid = np.zeros(64, dtype='<U2')\n",
    "    for index in xrange(64):\n",
    "        action = np.argmax(q[index,:])\n",
    "        grid[index] = A2A[action]\n",
    "    grid = np.reshape(grid, (8, 8), order='C')\n",
    "    print(grid)\n",
    "    return grid\n",
    "\n",
    "for iteration in range(1):\n",
    "    noise = np.random.normal(0, 1, (1, 64))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "    _ = show_policy(np.squeeze(gen_imgs, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_imgs = np.squeeze(gen_imgs, axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
